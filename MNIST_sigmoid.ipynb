{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_sigmoid.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUT3DcJwylz/XP9h05vuFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashmi2383/Machine-learning/blob/main/MNIST_sigmoid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjmBXNE26SJG"
      },
      "source": [
        "!pip install tensorflow keras numpy mnist matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEOWuK8u5j3Y",
        "outputId": "edaeacad-6416-4f4d-a9e3-8cfbb0845437"
      },
      "source": [
        "#import the packages/dependencies\r\n",
        "import numpy as np\r\n",
        "import mnist #get dataset from\r\n",
        "import matplotlib.pyplot as plt #Graph\r\n",
        "from keras.models import Sequential   #ANN\r\n",
        "from keras.layers import Dense #The layers in the ANN\r\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, ZeroPadding2D, Activation\r\n",
        "from keras.utils  import to_categorical\r\n",
        "\r\n",
        "#load the dataset\r\n",
        "train_images = mnist.train_images()  #training data images\r\n",
        "train_labels = mnist.train_labels()  #training data labels\r\n",
        "test_images = mnist.test_images()    #training data images\r\n",
        "test_labels = mnist.test_labels()    #training data labels\r\n",
        "\r\n",
        "#Normalizing the images. Normalize the pixel values from [0,255] to [-0.5,0.5] to make our network easier to train\r\n",
        "train_images = (train_images/255)  \r\n",
        "test_images = (test_images/255)\r\n",
        "#Flattening the images. Flatten each 28x28 image into a 784 dimensional vector to pass into the neural network\r\n",
        "train_images = train_images.reshape((-1,28,28,1))\r\n",
        "test_images = test_images.reshape((-1,28,28,1))\r\n",
        "#print the shape of our images\r\n",
        "print(train_images.shape)  #60,000 rows and 784 columns\r\n",
        "print(test_images.shape)   #10,000 rows and 784 columns\r\n",
        "\r\n",
        "#Build the model\r\n",
        "#3 layers\r\n",
        "model2 = Sequential()\r\n",
        "model2.add(ZeroPadding2D(padding=((1,0),(1,0))))\r\n",
        "model2.add(Conv2D(5,kernel_size=(5,5),strides=(2,2),input_shape=train_images.shape[1:]))\r\n",
        "model2.add(Activation('relu'))\r\n",
        "model2.add(Dense(100))\r\n",
        "#model2.add(MaxPool2D(pool_size=(3,3),strides=1))\r\n",
        "#model2.add(Activation('relu')) \r\n",
        "model2.add(Flatten())                #model.add(Dense(64, activation='relu'))\r\n",
        "model2.add(Dense(10,activation='sigmoid'))\r\n",
        "\r\n",
        "#compile the model\r\n",
        "#The loss function measures how well the model did on training and then tries to improve on it using the optimizer\r\n",
        "model2.compile(\r\n",
        "    optimizer='adam',\r\n",
        "    loss = 'categorical_crossentropy', #(class that are greater than 2)\r\n",
        "    metrics = ['accuracy']\r\n",
        ")\r\n",
        "\r\n",
        "#train the model\r\n",
        "model2.fit(\r\n",
        "    train_images,\r\n",
        "    to_categorical(train_labels),                 #Ex. 2 it expects [0,0,1,0,0,0,0,0,0,0] \r\n",
        "    epochs=20,                        #the number of iterations over the entire dataset to train on\r\n",
        "    batch_size=32,                   #number of samples per gradient update for training\r\n",
        "    validation_split=0.2\r\n",
        ")\r\n",
        "model2.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4117 - accuracy: 0.8802 - val_loss: 0.1190 - val_accuracy: 0.9636\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1053 - accuracy: 0.9687 - val_loss: 0.0929 - val_accuracy: 0.9722\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0805 - accuracy: 0.9743 - val_loss: 0.0863 - val_accuracy: 0.9743\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0714 - accuracy: 0.9780 - val_loss: 0.0923 - val_accuracy: 0.9718\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0613 - accuracy: 0.9805 - val_loss: 0.0879 - val_accuracy: 0.9747\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0566 - accuracy: 0.9826 - val_loss: 0.0881 - val_accuracy: 0.9763\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0553 - accuracy: 0.9825 - val_loss: 0.0911 - val_accuracy: 0.9743\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0476 - accuracy: 0.9848 - val_loss: 0.0882 - val_accuracy: 0.9752\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0465 - accuracy: 0.9846 - val_loss: 0.0891 - val_accuracy: 0.9743\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.0889 - val_accuracy: 0.9758\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0432 - accuracy: 0.9867 - val_loss: 0.0870 - val_accuracy: 0.9768\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.0938 - val_accuracy: 0.9759\n",
            "Epoch 13/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0397 - accuracy: 0.9868 - val_loss: 0.0850 - val_accuracy: 0.9775\n",
            "Epoch 14/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0373 - accuracy: 0.9870 - val_loss: 0.0978 - val_accuracy: 0.9751\n",
            "Epoch 15/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0353 - accuracy: 0.9881 - val_loss: 0.0961 - val_accuracy: 0.9764\n",
            "Epoch 16/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 0.0951 - val_accuracy: 0.9776\n",
            "Epoch 17/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0329 - accuracy: 0.9904 - val_loss: 0.1006 - val_accuracy: 0.9763\n",
            "Epoch 18/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0311 - accuracy: 0.9894 - val_loss: 0.1162 - val_accuracy: 0.9723\n",
            "Epoch 19/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0317 - accuracy: 0.9893 - val_loss: 0.0985 - val_accuracy: 0.9776\n",
            "Epoch 20/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.0974 - val_accuracy: 0.9768\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d_2 (ZeroPaddin (32, 29, 29, 1)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (32, 13, 13, 5)           130       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (32, 13, 13, 5)           0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (32, 13, 13, 100)         600       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (32, 16900)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (32, 10)                  169010    \n",
            "=================================================================\n",
            "Total params: 169,740\n",
            "Trainable params: 169,740\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-AdYcsm6HO7",
        "outputId": "b309d591-0531-4f98-8def-d2fd54e059fe"
      },
      "source": [
        "model2.layers[1].output\r\n",
        "\r\n",
        "#Evaluate the model\r\n",
        "model2.evaluate(\r\n",
        "    test_images,\r\n",
        "    to_categorical(test_labels)\r\n",
        ")\r\n",
        "\r\n",
        "#Save the model\r\n",
        "model2.save_weights('model2.h5')\r\n",
        "\r\n",
        "#predict on the first 5 test images\r\n",
        "predictions = model2.predict(test_images[:6])\r\n",
        "#print our model's prediction \r\n",
        "print(np.argmax(predictions, axis=1))\r\n",
        "print(test_labels[:6])\r\n",
        "\r\n",
        "print(model2.weights)\r\n",
        "np.save('model2.npy',model2.get_weights())\r\n",
        "\r\n",
        "print(model2.layers[1].get_weights()[0])\r\n",
        "#print(model.layers[1].get_weights()[1])\r\n",
        "\r\n",
        "print(model2.layers[0].get_config())\r\n",
        "\r\n",
        "print(model2.layers[1].get_config())\r\n",
        "\r\n",
        "print(model2.layers[2].get_config())\r\n",
        "\r\n",
        "print(model2.layers[3].get_config())\r\n",
        "\r\n",
        "print(model2.layers[4].get_config())\r\n",
        "\r\n",
        "print(model2.layers[5].get_config())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9771\n",
            "[7 2 1 0 4 1]\n",
            "[7 2 1 0 4 1]\n",
            "[<tf.Variable 'conv2d_2/kernel:0' shape=(5, 5, 1, 5) dtype=float32, numpy=\n",
            "array([[[[ 0.01848824, -0.2869611 ,  0.09377609,  0.16203804,\n",
            "           0.1786631 ]],\n",
            "\n",
            "        [[-0.00926721, -0.22012086,  0.1093236 ,  0.17964013,\n",
            "          -0.13487953]],\n",
            "\n",
            "        [[-0.3179518 , -0.2870587 ,  0.00460908, -0.279157  ,\n",
            "          -0.07699841]],\n",
            "\n",
            "        [[-0.21497494, -0.32558495, -0.26013258, -0.2495632 ,\n",
            "          -0.02049723]],\n",
            "\n",
            "        [[ 0.01364908, -0.2111339 , -0.17128448, -0.23359418,\n",
            "           0.1410223 ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.1088592 , -0.10952226,  0.0721378 ,  0.03807976,\n",
            "          -0.07877985]],\n",
            "\n",
            "        [[ 0.16935068, -0.26242438,  0.19928274,  0.21705064,\n",
            "           0.17067726]],\n",
            "\n",
            "        [[-0.4642618 , -0.28045076, -0.04958932, -0.01231184,\n",
            "           0.1146315 ]],\n",
            "\n",
            "        [[-0.50522256, -0.20609953,  0.20306972, -0.22163472,\n",
            "          -0.19374454]],\n",
            "\n",
            "        [[-0.20723788, -0.13522321,  0.22705065, -0.55702496,\n",
            "           0.12215488]]],\n",
            "\n",
            "\n",
            "       [[[-0.13491721, -0.47623387,  0.03897387, -0.00994232,\n",
            "          -0.08527672]],\n",
            "\n",
            "        [[ 0.19308276, -0.07306705,  0.16373944,  0.3747095 ,\n",
            "           0.22979818]],\n",
            "\n",
            "        [[ 0.16046807,  0.00343174,  0.07522829,  0.26081482,\n",
            "          -0.15106739]],\n",
            "\n",
            "        [[-0.2000719 ,  0.16307445,  0.2103784 , -0.25142527,\n",
            "          -0.0292765 ]],\n",
            "\n",
            "        [[-0.24471174,  0.1328678 ,  0.22183749, -0.7675501 ,\n",
            "           0.01692586]]],\n",
            "\n",
            "\n",
            "       [[[ 0.09660042, -0.21012112, -0.410928  ,  0.16415972,\n",
            "           0.20910056]],\n",
            "\n",
            "        [[ 0.22813697,  0.15137614,  0.15693311,  0.44180658,\n",
            "           0.15396023]],\n",
            "\n",
            "        [[ 0.36665127,  0.27315497,  0.30703542,  0.1400008 ,\n",
            "           0.1478459 ]],\n",
            "\n",
            "        [[ 0.2260655 ,  0.23274817, -0.04733301, -0.2966862 ,\n",
            "           0.24509892]],\n",
            "\n",
            "        [[ 0.00876633,  0.23678616,  0.08552387, -0.5492942 ,\n",
            "           0.11704538]]],\n",
            "\n",
            "\n",
            "       [[[ 0.19231622,  0.06961438, -0.497184  , -0.01762343,\n",
            "           0.11609179]],\n",
            "\n",
            "        [[ 0.1756753 ,  0.25203097, -0.48782676,  0.10925581,\n",
            "          -0.1299647 ]],\n",
            "\n",
            "        [[ 0.30261222,  0.1024991 , -0.34211728,  0.07349896,\n",
            "          -0.04030851]],\n",
            "\n",
            "        [[ 0.18958543,  0.04210327, -0.2853115 , -0.06745514,\n",
            "           0.21939327]],\n",
            "\n",
            "        [[ 0.00547182,  0.07056321, -0.42837843, -0.1208729 ,\n",
            "          -0.07889603]]]], dtype=float32)>, <tf.Variable 'conv2d_2/bias:0' shape=(5,) dtype=float32, numpy=\n",
            "array([-0.02966496, -0.01038502,  0.02332267,  0.00287413, -0.1040028 ],\n",
            "      dtype=float32)>, <tf.Variable 'dense_3/kernel:0' shape=(5, 100) dtype=float32, numpy=\n",
            "array([[ 6.22391522e-01, -1.92695558e-01, -7.42636994e-02,\n",
            "        -7.31633231e-02,  3.62643749e-01, -3.28857452e-02,\n",
            "         1.13832973e-01,  5.14177047e-03,  2.04738691e-01,\n",
            "        -1.26139164e-01,  1.80332452e-01, -4.19023097e-01,\n",
            "        -2.82583147e-01, -7.08189001e-03, -2.99702641e-02,\n",
            "        -1.38623133e-01, -3.30469105e-03,  5.93872070e-02,\n",
            "         2.93167233e-01,  2.81091854e-02,  2.59254813e-01,\n",
            "        -4.81620580e-02, -1.80645864e-02, -1.29203005e-02,\n",
            "         6.01661801e-02, -1.83987767e-01, -8.59253109e-02,\n",
            "        -4.87197675e-02, -1.60109743e-01, -8.07676762e-02,\n",
            "        -2.89354652e-01, -2.43653283e-02,  8.81323069e-02,\n",
            "         7.01502785e-02,  2.81107992e-01, -4.63323861e-01,\n",
            "        -2.00649858e-01,  1.30488332e-02,  1.95417646e-02,\n",
            "         2.31171697e-02,  1.00005545e-01, -2.23940894e-01,\n",
            "        -5.88195883e-02,  1.13505729e-01, -1.21031076e-01,\n",
            "        -2.46390030e-01,  1.24657355e-01, -1.16734520e-01,\n",
            "         1.03624739e-01, -2.40609407e-01,  1.00475773e-02,\n",
            "         3.15407693e-01,  6.71564508e-03, -4.74985270e-03,\n",
            "        -4.16194974e-03,  3.27891596e-02,  2.53945198e-02,\n",
            "         3.27185988e-01,  3.43805730e-01, -3.88541818e-01,\n",
            "        -3.50103294e-03,  4.16160464e-01,  1.37362955e-02,\n",
            "        -4.91134316e-01,  1.10114664e-01,  7.36204311e-02,\n",
            "         1.84817448e-01, -9.19155194e-04,  2.61045188e-01,\n",
            "        -2.00970322e-02,  3.20298195e-01,  3.16002607e-01,\n",
            "        -8.63069594e-02, -1.71949059e-01, -5.13287961e-01,\n",
            "         2.66865104e-01,  4.28993553e-01, -3.36500376e-01,\n",
            "        -1.18250335e-02, -8.63728896e-02,  9.30618718e-02,\n",
            "         3.66054565e-01,  1.37622118e-01,  1.37236819e-01,\n",
            "         2.31191531e-01, -1.60954461e-01,  5.76660410e-02,\n",
            "        -7.70378858e-02, -1.49517385e-02, -4.19810452e-02,\n",
            "         1.26701817e-02, -1.04472358e-02,  1.80201173e-01,\n",
            "         3.57831568e-02, -1.40000721e-02,  2.65825868e-01,\n",
            "         7.69251511e-02, -2.71500815e-02,  1.14936136e-01,\n",
            "        -8.66035074e-02],\n",
            "       [-1.50814563e-01,  2.78676450e-01, -3.78932953e-02,\n",
            "        -9.45988297e-02, -3.55932862e-01,  4.20680456e-02,\n",
            "        -1.53875142e-01, -1.39726838e-02, -3.58018011e-01,\n",
            "         7.13774338e-02, -7.02318788e-01,  2.68972874e-01,\n",
            "         6.60648406e-01, -9.56928357e-03,  5.70270175e-04,\n",
            "         2.10982218e-01, -3.00578237e-01,  1.30201831e-01,\n",
            "        -2.39537358e-01, -1.79062057e-02, -3.06432217e-01,\n",
            "         1.92491170e-02,  9.69630256e-02, -1.54473875e-02,\n",
            "         6.66385517e-02,  2.52503961e-01,  3.33009660e-01,\n",
            "         4.81825359e-02,  3.50180417e-01,  9.86453295e-02,\n",
            "         2.08112672e-01,  7.89136589e-02,  8.29694569e-02,\n",
            "        -2.36760318e-01, -8.41788575e-02,  4.33192521e-01,\n",
            "         1.94851920e-01, -1.25228325e-02, -5.47095295e-03,\n",
            "        -9.21127796e-02, -2.37857297e-01, -3.33991088e-03,\n",
            "         1.90607339e-01, -2.87025124e-01,  2.08044857e-01,\n",
            "         2.60548562e-01, -3.61252725e-02,  2.99606115e-01,\n",
            "         6.54963851e-02,  2.98034519e-01, -6.93625165e-03,\n",
            "        -5.64049363e-01,  2.53932979e-02,  1.72303468e-02,\n",
            "         2.53805928e-02, -6.30414858e-02,  8.93938076e-03,\n",
            "        -2.82779574e-01, -3.88921499e-01,  6.28482252e-02,\n",
            "        -2.12107882e-01, -1.20430022e-01,  1.22839594e-02,\n",
            "        -5.01668416e-02,  4.28222954e-01,  4.84510437e-02,\n",
            "        -1.61389858e-01, -1.03016056e-01,  2.58394301e-01,\n",
            "        -3.08523723e-03,  1.38917025e-02, -8.36362615e-02,\n",
            "         7.66062737e-02,  1.34726867e-01,  2.61811823e-01,\n",
            "         8.45420510e-02, -6.15590930e-01,  4.74528849e-01,\n",
            "        -3.59575427e-03,  9.25076567e-03, -7.85605162e-02,\n",
            "        -3.45810235e-01, -1.08136283e-02, -1.17525220e-01,\n",
            "         2.44681284e-01, -6.37426600e-02, -1.40963256e-01,\n",
            "         9.78720933e-02,  2.73816418e-02, -1.84928671e-01,\n",
            "        -1.38481539e-02,  1.27086346e-03, -3.25509161e-01,\n",
            "        -1.59937739e-02,  1.27133550e-02,  4.07689065e-01,\n",
            "        -1.74934283e-01, -2.83937939e-02, -1.22040570e-01,\n",
            "        -4.83722895e-01],\n",
            "       [ 2.46082664e-01,  4.97686230e-02, -7.95196071e-02,\n",
            "         2.70042509e-01, -7.51844347e-02, -6.19090319e-01,\n",
            "        -1.51464537e-01, -4.36239596e-03,  1.51493222e-01,\n",
            "        -3.79959308e-02,  2.07873419e-01, -2.24257112e-01,\n",
            "        -1.87590793e-01, -1.48050636e-02, -1.23249963e-01,\n",
            "         2.80809045e-01, -8.15299060e-03,  7.25821592e-03,\n",
            "         1.31506264e-01, -9.05846134e-02, -2.19899282e-01,\n",
            "        -4.26705480e-02,  2.90990800e-01,  2.56606527e-02,\n",
            "         1.45049065e-01, -5.13788685e-02,  4.30920869e-01,\n",
            "        -7.16319233e-02,  1.46293029e-01, -8.00049752e-02,\n",
            "        -5.43288365e-02,  3.90760377e-02,  1.50293782e-01,\n",
            "        -5.08401357e-02,  4.06993687e-01, -1.85752198e-01,\n",
            "        -1.40046347e-02, -1.12400781e-02, -8.92587192e-03,\n",
            "        -2.32997239e-02, -8.38114172e-02, -1.72727644e-01,\n",
            "         3.52910340e-01, -9.62637663e-01, -1.99022204e-01,\n",
            "        -1.91623434e-01,  3.50613892e-02, -5.92623241e-02,\n",
            "         3.64989221e-01, -2.02838451e-01, -2.71132193e-03,\n",
            "         1.24532856e-01,  3.59700859e-01,  1.57058556e-02,\n",
            "         5.36136702e-02, -1.09398467e-02, -1.59569411e-03,\n",
            "         1.68140694e-01,  3.14183712e-01, -2.71018725e-02,\n",
            "        -4.32394892e-02,  7.01052725e-01,  1.47424208e-03,\n",
            "         8.41264203e-02,  4.20857877e-01,  1.31166264e-01,\n",
            "         1.16081014e-01, -6.24245740e-02,  3.75032097e-01,\n",
            "        -8.00317794e-04,  7.09196553e-02,  1.43586159e-01,\n",
            "         3.54545504e-01, -3.15495104e-01, -3.52969021e-01,\n",
            "         2.35022783e-01, -1.80051941e-02,  3.44512500e-02,\n",
            "         2.36392636e-02, -3.22724223e-01, -1.94629829e-03,\n",
            "         1.16858289e-01,  3.95195782e-02, -2.50001792e-02,\n",
            "         4.01737988e-01, -2.06108183e-01,  1.73258603e-01,\n",
            "         9.39335003e-02,  1.45444572e-02, -3.10068667e-01,\n",
            "        -1.18365828e-02, -4.35998105e-03,  1.34810388e-01,\n",
            "        -1.37887910e-01,  8.22090730e-03,  2.33321875e-01,\n",
            "         2.26156339e-01, -2.49274373e-02,  1.94118712e-02,\n",
            "         2.15760320e-02],\n",
            "       [-6.11318946e-01,  8.35944060e-03, -2.72460729e-02,\n",
            "         3.90307382e-02, -2.67361939e-01,  3.15428413e-02,\n",
            "        -6.73764050e-02, -1.45346532e-02, -3.37590456e-01,\n",
            "        -4.93763089e-02, -9.01055932e-02,  1.88902542e-01,\n",
            "         1.51095286e-01,  5.16168959e-03,  4.74759862e-02,\n",
            "         6.42464310e-02, -1.48709610e-01,  9.32188146e-03,\n",
            "        -1.09844789e-01, -5.56478612e-02, -1.64441749e-01,\n",
            "        -2.53451485e-02, -7.60808766e-01,  3.85753475e-02,\n",
            "         1.18734412e-01,  1.09578505e-01, -7.69505382e-01,\n",
            "         7.11541101e-02, -3.85950685e-01,  8.02446678e-02,\n",
            "        -9.79315042e-02, -1.77623443e-02, -7.84562901e-02,\n",
            "        -6.43144622e-02, -9.52146649e-02,  3.68166238e-01,\n",
            "         1.20054215e-01, -7.78849656e-03, -6.77353761e-04,\n",
            "        -5.42628132e-02, -7.40940452e-01,  1.97722480e-01,\n",
            "         4.15106155e-02, -1.24880813e-01,  1.45447716e-01,\n",
            "        -6.09485209e-02, -1.44237205e-01,  1.46361813e-01,\n",
            "        -9.28226952e-03,  1.69941410e-01, -1.22488327e-02,\n",
            "        -2.53984392e-01, -3.81587446e-02, -9.13820881e-03,\n",
            "         1.14978030e-02, -7.05415010e-03, -1.50472103e-02,\n",
            "        -4.85850610e-02, -2.19028071e-01,  4.58485305e-01,\n",
            "         1.05097540e-01, -1.05129652e-01,  1.13947829e-03,\n",
            "         6.41781151e-01, -1.21255562e-01,  1.71543341e-02,\n",
            "        -3.27591091e-01, -3.47203482e-03, -7.93380514e-02,\n",
            "         1.13500785e-02, -2.23559856e-01, -4.34314042e-01,\n",
            "        -1.94166943e-01,  1.22421741e-01,  3.24260086e-01,\n",
            "         4.93034720e-02, -2.54432648e-01,  4.43701148e-02,\n",
            "        -6.32776297e-04, -6.74548233e-03, -3.78099345e-02,\n",
            "         3.86680841e-01, -4.66678925e-02, -2.34472733e-02,\n",
            "        -6.50383085e-02,  2.00895350e-02, -1.35720998e-01,\n",
            "         4.74593081e-02,  1.25527726e-02,  2.67652810e-01,\n",
            "        -9.15306620e-03, -3.82054388e-03, -8.69668424e-02,\n",
            "         4.50811675e-03,  9.92097333e-03, -1.71660647e-01,\n",
            "        -1.58898130e-01, -4.10502367e-02, -9.74566787e-02,\n",
            "        -1.15100719e-01],\n",
            "       [ 9.78889316e-03, -1.50433689e-01,  1.80591285e-01,\n",
            "        -3.67964501e-03,  8.16210732e-02, -5.30425273e-02,\n",
            "        -9.75090079e-03,  1.96333975e-03,  2.43818119e-01,\n",
            "         2.00364128e-01, -2.97584087e-02,  2.59081721e-01,\n",
            "         1.15244100e-02, -2.38463283e-03, -5.26654981e-02,\n",
            "        -1.49876140e-02,  3.53227317e-01, -1.06578484e-01,\n",
            "        -2.11096376e-01,  2.12598555e-02,  9.26489457e-02,\n",
            "         1.04393780e-01,  1.38343245e-01, -6.15151860e-02,\n",
            "        -3.33158851e-01,  6.05968796e-02, -2.05544457e-01,\n",
            "        -8.04579780e-02, -1.85044616e-01,  2.13843305e-03,\n",
            "         2.17285991e-01, -8.66532177e-02,  4.71575409e-02,\n",
            "         1.70768246e-01, -3.49213839e-01,  4.20139544e-02,\n",
            "         5.83384670e-02, -1.24505092e-03, -3.17667462e-02,\n",
            "         9.07519460e-02,  5.10445237e-01, -1.00050621e-01,\n",
            "        -2.04468779e-02,  1.58028349e-01, -3.31265070e-02,\n",
            "         1.56681731e-01, -7.39996806e-02, -1.96968839e-01,\n",
            "        -8.85003433e-02, -8.25913772e-02,  1.24530809e-04,\n",
            "         7.26436675e-02,  6.13983870e-02,  1.55516854e-03,\n",
            "        -7.42439413e-04,  2.75426414e-02,  3.10809538e-03,\n",
            "        -2.93009907e-01, -1.49656028e-01,  3.86394784e-02,\n",
            "         1.21744327e-01, -1.90669060e-01, -1.69910360e-02,\n",
            "        -1.91706225e-01, -1.37129486e-01, -1.96353048e-01,\n",
            "        -3.45858745e-02,  1.01442717e-01, -9.59023088e-02,\n",
            "        -2.29164376e-03, -1.33265063e-01, -1.50241926e-01,\n",
            "         7.05731288e-02, -4.97553833e-02,  1.67929262e-01,\n",
            "        -4.88418877e-01,  1.29763678e-01,  6.39019087e-02,\n",
            "        -1.91896409e-03,  2.15901911e-01, -4.10414711e-02,\n",
            "        -1.62056521e-01, -9.58913118e-02,  5.07914685e-02,\n",
            "        -8.41538906e-02,  3.13076407e-01,  2.15448454e-01,\n",
            "         3.44790821e-03, -2.83401459e-03,  2.43212488e-02,\n",
            "        -4.94299131e-03, -1.41742150e-03, -9.38662365e-02,\n",
            "        -4.55263928e-02, -1.36858050e-03, -4.91412655e-02,\n",
            "         1.82356268e-01,  1.17315806e-01, -1.40675688e-02,\n",
            "         2.79804975e-01]], dtype=float32)>, <tf.Variable 'dense_3/bias:0' shape=(100,) dtype=float32, numpy=\n",
            "array([-9.8891929e-03,  4.2889924e-03, -1.8227887e-03, -5.5463593e-03,\n",
            "        1.9722183e-03,  2.3480257e-02,  8.6981431e-03,  4.0677320e-03,\n",
            "       -5.1609012e-03, -2.4796370e-03, -1.3198993e-03,  4.3263086e-03,\n",
            "        2.2363558e-03, -1.0236889e-03,  1.0029725e-02, -1.2191203e-02,\n",
            "       -2.4374151e-03, -6.6357676e-04,  1.4355907e-03,  4.0954999e-03,\n",
            "        5.3244820e-03, -3.2013480e-03, -6.8094805e-03,  2.4328232e-03,\n",
            "        5.2513764e-04, -4.3736654e-03, -8.2790451e-03,  6.5048290e-03,\n",
            "        6.3899846e-04, -2.0049682e-03,  3.7286272e-03,  4.3567452e-03,\n",
            "       -1.5729668e-02, -1.5149112e-03, -9.3013691e-03,  5.2051265e-03,\n",
            "       -2.6648873e-03,  2.5036163e-03,  3.7616943e-03, -5.3264113e-04,\n",
            "        2.1979094e-03,  1.4719656e-02, -2.1505678e-02,  3.4285754e-02,\n",
            "        2.0178645e-03,  7.3564448e-03,  4.5932634e-03,  3.7780944e-03,\n",
            "       -2.0031935e-02,  8.6578280e-03,  5.5408808e-03, -1.6133973e-03,\n",
            "       -1.9349711e-02,  1.3969640e-03, -4.9334862e-03, -6.9482834e-04,\n",
            "        1.2808942e-03, -7.0306961e-04, -5.0906851e-03,  2.5871301e-03,\n",
            "       -1.7512735e-03, -2.8148819e-02, -7.4886275e-04,  8.9225383e-04,\n",
            "       -2.1165488e-02, -6.5771535e-05,  6.8621780e-04, -9.6284895e-04,\n",
            "       -2.7347926e-02,  2.2795561e-03, -3.8809993e-03, -2.5856399e-03,\n",
            "       -1.0253561e-02,  1.5847305e-02,  1.2543278e-02, -4.8030340e-03,\n",
            "       -1.0368724e-03,  4.5396417e-05,  1.4776522e-03,  5.7657431e-03,\n",
            "        4.7624256e-03, -5.6627220e-03, -7.4303003e-05, -3.9541642e-03,\n",
            "       -2.8907254e-02,  2.4836441e-03, -1.0267451e-02, -5.4295966e-03,\n",
            "       -2.5105774e-03,  1.0711028e-02,  1.4345730e-03, -1.8580362e-03,\n",
            "        5.0745583e-03,  6.0394346e-03, -1.7935046e-03, -1.8975986e-02,\n",
            "       -9.3548037e-03, -3.5212953e-03,  1.8034303e-03,  3.0939793e-03],\n",
            "      dtype=float32)>, <tf.Variable 'dense_4/kernel:0' shape=(16900, 10) dtype=float32, numpy=\n",
            "array([[ 0.1958362 ,  0.25747147, -0.45726407, ...,  0.1305327 ,\n",
            "         0.01396434,  0.4226268 ],\n",
            "       [-0.00892229,  0.02081091, -0.03750746, ..., -0.0587813 ,\n",
            "         0.04602554,  0.06034994],\n",
            "       [-0.06674538,  0.10183395, -0.00513126, ..., -0.02718861,\n",
            "        -0.00381109, -0.06091837],\n",
            "       ...,\n",
            "       [ 0.0578342 ,  0.07123104, -0.05755365, ...,  0.01536417,\n",
            "        -0.01356607, -0.03545113],\n",
            "       [ 0.08547477,  0.01133223, -0.03280411, ...,  0.12647167,\n",
            "        -0.01337406,  0.03916172],\n",
            "       [-0.07668464, -0.02840275,  0.2342186 , ...,  0.11276587,\n",
            "         0.00551348, -0.29003873]], dtype=float32)>, <tf.Variable 'dense_4/bias:0' shape=(10,) dtype=float32, numpy=\n",
            "array([ 0.01889052,  0.044336  ,  0.26380053, -0.25071213, -0.17380722,\n",
            "        0.08712828, -0.10698099,  0.03700084,  0.20646293, -0.18376684],\n",
            "      dtype=float32)>]\n",
            "[[[[ 0.01848824 -0.2869611   0.09377609  0.16203804  0.1786631 ]]\n",
            "\n",
            "  [[-0.00926721 -0.22012086  0.1093236   0.17964013 -0.13487953]]\n",
            "\n",
            "  [[-0.3179518  -0.2870587   0.00460908 -0.279157   -0.07699841]]\n",
            "\n",
            "  [[-0.21497494 -0.32558495 -0.26013258 -0.2495632  -0.02049723]]\n",
            "\n",
            "  [[ 0.01364908 -0.2111339  -0.17128448 -0.23359418  0.1410223 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.1088592  -0.10952226  0.0721378   0.03807976 -0.07877985]]\n",
            "\n",
            "  [[ 0.16935068 -0.26242438  0.19928274  0.21705064  0.17067726]]\n",
            "\n",
            "  [[-0.4642618  -0.28045076 -0.04958932 -0.01231184  0.1146315 ]]\n",
            "\n",
            "  [[-0.50522256 -0.20609953  0.20306972 -0.22163472 -0.19374454]]\n",
            "\n",
            "  [[-0.20723788 -0.13522321  0.22705065 -0.55702496  0.12215488]]]\n",
            "\n",
            "\n",
            " [[[-0.13491721 -0.47623387  0.03897387 -0.00994232 -0.08527672]]\n",
            "\n",
            "  [[ 0.19308276 -0.07306705  0.16373944  0.3747095   0.22979818]]\n",
            "\n",
            "  [[ 0.16046807  0.00343174  0.07522829  0.26081482 -0.15106739]]\n",
            "\n",
            "  [[-0.2000719   0.16307445  0.2103784  -0.25142527 -0.0292765 ]]\n",
            "\n",
            "  [[-0.24471174  0.1328678   0.22183749 -0.7675501   0.01692586]]]\n",
            "\n",
            "\n",
            " [[[ 0.09660042 -0.21012112 -0.410928    0.16415972  0.20910056]]\n",
            "\n",
            "  [[ 0.22813697  0.15137614  0.15693311  0.44180658  0.15396023]]\n",
            "\n",
            "  [[ 0.36665127  0.27315497  0.30703542  0.1400008   0.1478459 ]]\n",
            "\n",
            "  [[ 0.2260655   0.23274817 -0.04733301 -0.2966862   0.24509892]]\n",
            "\n",
            "  [[ 0.00876633  0.23678616  0.08552387 -0.5492942   0.11704538]]]\n",
            "\n",
            "\n",
            " [[[ 0.19231622  0.06961438 -0.497184   -0.01762343  0.11609179]]\n",
            "\n",
            "  [[ 0.1756753   0.25203097 -0.48782676  0.10925581 -0.1299647 ]]\n",
            "\n",
            "  [[ 0.30261222  0.1024991  -0.34211728  0.07349896 -0.04030851]]\n",
            "\n",
            "  [[ 0.18958543  0.04210327 -0.2853115  -0.06745514  0.21939327]]\n",
            "\n",
            "  [[ 0.00547182  0.07056321 -0.42837843 -0.1208729  -0.07889603]]]]\n",
            "{'name': 'zero_padding2d_2', 'trainable': True, 'dtype': 'float32', 'padding': ((1, 0), (1, 0)), 'data_format': 'channels_last'}\n",
            "{'name': 'conv2d_2', 'trainable': True, 'batch_input_shape': (None, 28, 28, 1), 'dtype': 'float32', 'filters': 5, 'kernel_size': (5, 5), 'strides': (2, 2), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'activation_2', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'}\n",
            "{'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}\n",
            "{'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}